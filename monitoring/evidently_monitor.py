# monitoring/evidently_monitor.py
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Union, Optional
import pandas as pd
import numpy as np

from dotenv import find_dotenv, load_dotenv
import logging

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

env_path = find_dotenv()
load_dotenv(env_path, override=True)


def log_prediction(
    features: Union[Dict, pd.DataFrame, List],
    prediction: Union[int, float, List, np.ndarray],
    actual: Optional[Union[int, float, List, np.ndarray]] = None,
    timestamp: Optional[datetime] = None,
    log_file: str = 'data/monitoring_predictions.jsonl'
):
    """
    Enregistre une prÃ©diction pour le monitoring Evidently
    
    Args:
        features: Features utilisÃ©es pour la prÃ©diction (dict, DataFrame ou list)
        prediction: PrÃ©diction(s) du modÃ¨le
        actual: Valeur rÃ©elle (optionnel, si disponible)
        timestamp: Horodatage (par dÃ©faut: maintenant)
        log_file: Chemin du fichier de log
    """
    logging.info("ðŸ“ Logging de la prÃ©diction pour le monitoring Evidently")
    if timestamp is None:
        timestamp = datetime.now()
    
    # Normaliser les features en liste de dictionnaires
    if isinstance(features, pd.DataFrame):
        features_list = features.to_dict('records')
    elif isinstance(features, dict):
        features_list = [features]
    elif isinstance(features, list):
        features_list = features
    else:
        raise ValueError(f"Type de features non supportÃ©: {type(features)}")
    
    # Normaliser les prÃ©dictions en liste
    if isinstance(prediction, (int, float, np.integer, np.floating)):
        predictions_list = [prediction]
    elif isinstance(prediction, np.ndarray):
        predictions_list = prediction.tolist()
    elif isinstance(prediction, list):
        predictions_list = prediction
    else:
        predictions_list = [prediction]
    
    # Normaliser les actuals en liste (si fournis)
    actuals_list = None
    if actual is not None:
        if isinstance(actual, (int, float, np.integer, np.floating)):
            actuals_list = [actual]
        elif isinstance(actual, np.ndarray):
            actuals_list = actual.tolist()
        elif isinstance(actual, list):
            actuals_list = actual
        else:
            actuals_list = [actual]
    
    # CrÃ©er l'objet Ã  logger
    logging.info("ðŸ“ PrÃ©paration de l'entrÃ©e de log")
    log_entry = {
        'timestamp': timestamp.isoformat(),
        'predictions': predictions_list,
        'features': features_list,
        'actuals': actuals_list
    }
    logging.info(f"ðŸ“ EntrÃ©e de log prÃ©parÃ©e : pred={predictions_list}, features={features_list}")
    
    # Obtenir le rÃ©pertoire parent de la base de la librairie
    lib_dir = Path(__file__).parent.parent
    
    # Construire le chemin complet du fichier de log
    log_path = lib_dir / log_file
    
    # CrÃ©er le rÃ©pertoire parent si nÃ©cessaire
    log_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Ã‰crire dans le fichier JSONL (une ligne par prÃ©diction)
    try:
        logging.info(f"ðŸ“ Ã‰criture de la prÃ©diction dans le fichier {log_path}")
        with open(log_path, 'a') as f:
            f.write(json.dumps(log_entry) + '\n')
    except Exception as e:
        print(f"âš ï¸ Erreur lors du logging de la prÃ©diction: {e}")


def log_batch_predictions(
    features_df: pd.DataFrame,
    predictions: Union[List, np.ndarray],
    actuals: Optional[Union[List, np.ndarray]] = None,
    timestamp: Optional[datetime] = None,
    log_file: str = '/data/monitoring_predictions.jsonl'
):
    """
    Enregistre un batch de prÃ©dictions pour le monitoring
    
    Args:
        features_df: DataFrame contenant les features
        predictions: Array/liste des prÃ©dictions
        actuals: Array/liste des valeurs rÃ©elles (optionnel)
        timestamp: Horodatage (par dÃ©faut: maintenant)
        log_file: Chemin du fichier de log
    """
    if timestamp is None:
        timestamp = datetime.now()
    
    # Convertir en listes si nÃ©cessaire
    if isinstance(predictions, np.ndarray):
        predictions = predictions.tolist()
    
    if actuals is not None and isinstance(actuals, np.ndarray):
        actuals = actuals.tolist()
    
    # Logger
    log_prediction(
        features=features_df,
        prediction=predictions,
        actual=actuals,
        timestamp=timestamp,
        log_file=log_file
    )


def get_logged_predictions(
    hours: int = 24,
    log_file: str = '/data/monitoring_predictions.jsonl'
) -> pd.DataFrame:
    """
    RÃ©cupÃ¨re les prÃ©dictions loggÃ©es des derniÃ¨res X heures
    
    Args:
        hours: Nombre d'heures Ã  rÃ©cupÃ©rer
        log_file: Chemin du fichier de log
        
    Returns:
        DataFrame avec toutes les prÃ©dictions
    """
    log_path = Path(log_file)
    
    if not log_path.exists():
        return pd.DataFrame()
    
    from datetime import timedelta
    
    cutoff_time = datetime.now() - timedelta(hours=hours)
    predictions_list = []
    
    with open(log_path, 'r') as f:
        for line in f:
            try:
                data = json.loads(line)
                timestamp = datetime.fromisoformat(data['timestamp'])
                
                if timestamp >= cutoff_time:
                    predictions_list.append(data)
            except Exception:
                continue
    
    if not predictions_list:
        return pd.DataFrame()
    
    # Convertir en DataFrame
    all_features = []
    all_predictions = []
    all_actuals = []
    
    for pred in predictions_list:
        all_features.extend(pred['features'])
        all_predictions.extend(pred['predictions'])
        if pred.get('actuals'):
            all_actuals.extend(pred['actuals'])
    
    df = pd.DataFrame(all_features)
    df['prediction'] = all_predictions
    
    if all_actuals:
        df['target'] = all_actuals
    
    return df